# modules/document_analysis_page.py

import streamlit as st
import os # í™˜ê²½ ë³€ìˆ˜ ì ‘ê·¼ì„ ìœ„í•´ í•„ìš”
from loguru import logger # ë¡œê¹…ì„ ìœ„í•´ í•„ìš”

# --- ëª¨ë“ˆ ì„í¬íŠ¸ ---
from modules import ai_service # AI ì„œë¹„ìŠ¤ ëª¨ë“ˆ
from modules import document_processor # ìƒˆë¡œ ë§Œë“  ë¬¸ì„œ ì²˜ë¦¬ ëª¨ë“ˆ

from langchain.memory import StreamlitChatMessageHistory # Langchain Streamlit í†µí•©


def document_analysis_page():
    """
    ë¬¸ì„œ ê¸°ë°˜ QA ì±—ë´‡ ë° íŠ¹ì•½ ìƒì„± ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” í˜ì´ì§€ì…ë‹ˆë‹¤.
    """
    st.title("ğŸ“„ _Private Data :red[QA Chat]_")

    # ë©”ì¸ìœ¼ë¡œ ëŒì•„ê°€ê¸° ë²„íŠ¼
    if st.button("â¬…ï¸ ë©”ì¸ìœ¼ë¡œ"):
        st.session_state.page = "landing"
        st.rerun()
    st.markdown("---") # ë²„íŠ¼ ì•„ë˜ êµ¬ë¶„ì„  ì¶”ê°€

    # Potens API í‚¤ ë¡œë“œ (main_app.pyì—ì„œ ë¡œë“œëœ ê²ƒì„ ì‚¬ìš©)
    POTENS_API_KEY = os.getenv("POTENS_API_KEY")
    if not POTENS_API_KEY:
        st.error("ğŸš¨ ì˜¤ë¥˜: Potens.dev API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return # API í‚¤ ì—†ìœ¼ë©´ í˜ì´ì§€ ê¸°ëŠ¥ ë¹„í™œì„±í™”

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "vectordb" not in st.session_state:
        st.session_state.vectordb = None
    if 'messages' not in st.session_state:
        st.session_state.messages = [{
            "role": "assistant",
            "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”."
        }]
    if "docs" not in st.session_state: # íŠ¹ì•½ ìƒì„± ê¸°ëŠ¥ì—ì„œ í•„ìš”
        st.session_state.docs = []


    with st.sidebar:
        selected_menu = st.selectbox("ğŸ“Œ ë©”ë‰´ ì„ íƒ", ["ìµœì‹  QA", "íŠ¹ì•½ ìƒì„±"])
        uploaded_files = st.file_uploader("ğŸ“ ë¬¸ì„œ ì—…ë¡œë“œ", type=['pdf', 'docx', 'pptx', 'txt'], accept_multiple_files=True)
        process = st.button("ğŸ“š ë¬¸ì„œ ì²˜ë¦¬")

    if process:
        if not uploaded_files:
            st.warning("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            st.stop()

        with st.spinner("ë¬¸ì„œë¥¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
            docs = document_processor.get_text(uploaded_files)
            chunks = document_processor.get_text_chunks(docs)
            vectordb = document_processor.get_vectorstore(chunks)
            st.session_state.vectordb = vectordb
            st.session_state.docs = docs # 'docs' ì„¸ì…˜ ìƒíƒœì— ì €ì¥ (íŠ¹ì•½ ìƒì„±ì—ì„œ ì‚¬ìš©)
            st.success("âœ… ë¬¸ì„œ ë¶„ì„ ì™„ë£Œ! ë©”ë‰´ë¥¼ ì„ íƒí•´ ì§„í–‰í•˜ì„¸ìš”.")
            st.session_state.messages = [{ # ë¬¸ì„œ ì²˜ë¦¬ í›„ ë©”ì‹œì§€ ì´ˆê¸°í™”
                "role": "assistant",
                "content": "ë¬¸ì„œ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì§ˆë¬¸í•˜ê±°ë‚˜ íŠ¹ì•½ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            }]
            st.rerun()


    if selected_menu == "ìµœì‹  QA":
        for msg in st.session_state.messages:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

        history = StreamlitChatMessageHistory(key="chat_messages") # StreamlitChatMessageHistory ì´ˆê¸°í™”

        if query := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."):
            st.session_state.messages.append({"role": "user", "content": query})

            with st.chat_message("user"):
                st.markdown(query)

            with st.chat_message("assistant"):
                if not st.session_state.vectordb:
                    st.warning("ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.")
                    st.stop()

                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                    retriever = st.session_state.vectordb.as_retriever(search_type="similarity", k=3)
                    docs = retriever.get_relevant_documents(query)

                    context = "\n\n".join([doc.page_content for doc in docs])
                    final_prompt = f"""ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

[ë¬¸ì„œ ë‚´ìš©]:
{context}

[ì§ˆë¬¸]:
{query}

[ë‹µë³€]:
"""
                    # ai_service ëª¨ë“ˆì˜ retry_ai_call í•¨ìˆ˜ ì‚¬ìš©
                    response_dict = ai_service.retry_ai_call(final_prompt, POTENS_API_KEY)
                    answer = ai_service.clean_ai_response_text(response_dict.get("text", response_dict.get("error", "AI ì‘ë‹µ ì‹¤íŒ¨.")))

                    st.markdown(answer)
                    with st.expander("ğŸ“„ ì°¸ê³  ë¬¸ì„œ"):
                        for doc_ref in docs:
                            st.markdown(f"**ì¶œì²˜**: {doc_ref.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                            st.markdown(doc_ref.page_content)

                    st.session_state.messages.append({"role": "assistant", "content": answer})

    elif selected_menu == "íŠ¹ì•½ ìƒì„±":
        st.subheader("ğŸ“‘ ë³´í—˜ íŠ¹ì•½ ìƒì„±ê¸°")

        if "docs" not in st.session_state or not st.session_state.docs:
            st.warning("ë¬¸ì„œë¥¼ ë¨¼ì € ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
            st.stop()

        all_text = "\n\n".join([doc.page_content for doc in st.session_state.docs])
        prompt = f"""
ë„ˆëŠ” ìë™ì°¨ ë³´í—˜ì„ ì„¤ê³„í•˜ê³  ìˆëŠ” ë³´í—˜ì‚¬ ì§ì›ì´ì•¼.  
ë‹¤ìŒ ì¡°ê±´ì— ë”°ë¼ ìë™ì°¨ ë³´í—˜ **íŠ¹ì•½**ì„ ìƒì„±í•´ì¤˜.

[ê¸°ë³¸ ì¡°ê±´]
- ìë™ì°¨ ë³´í—˜ í‘œì¤€ì•½ê´€ì„ ì°¸ê³ í•´ì¤˜.
- ì•„ë˜ì˜ êµ¬ì„± í•­ëª©ì„ ë°˜ë“œì‹œ í¬í•¨í•´ì¤˜:
  1. íŠ¹ì•½ì˜ ëª…ì¹­
  2. íŠ¹ì•½ì˜ ëª©ì 
  3. ë³´ì¥ ë²”ìœ„
  4. ë³´í—˜ê¸ˆ ì§€ê¸‰ ì¡°ê±´
  5. ë³´í—˜ë£Œ ì‚°ì • ë°©ì‹
  6. ë©´ì±… ì‚¬í•­
  7. íŠ¹ì•½ì˜ ì ìš© ê¸°ê°„
  8. ê¸°íƒ€ íŠ¹ë³„ ì¡°ê±´

[ê¸°íš ëª©ì ]
- ì´ íŠ¹ì•½ì€ **ë³´í—˜ ìƒí’ˆ ê¸°íš ì´ˆê¸° ë‹¨ê³„**ì—ì„œ **íŠ¸ë Œë“œ ì¡°ì‚¬ ë° ë°©í–¥ì„± ë„ì¶œì— ë„ì›€**ì´ ë˜ëŠ” ëª©ì ìœ¼ë¡œ ì‘ì„±ë¼ì•¼ í•´.
- ì°½ì˜ì ì¸ ìš”ì†Œë¥¼ í¬í•¨í•´ë„ ì¢‹ì§€ë§Œ, **ì‹¤ì œ ìƒí’ˆí™” ê°€ëŠ¥ì„±**ì„ ê³ ë ¤í•´ì„œ êµ¬ì„±í•´ì¤˜.
- ìƒˆë¡œìš´ ê¸°ìˆ (ì˜ˆ: ë¸”ë™ë°•ìŠ¤, ììœ¨ì£¼í–‰, ìŠ¤ë§ˆíŠ¸í° ì•± ë“±)ì´ë‚˜ ìµœê·¼ ì‚¬íšŒì  ì´ìŠˆ(ì˜ˆ: ê³ ë ¹ ìš´ì „ì ì¦ê°€, ì´ë¥œì°¨ ë°°ë‹¬ ì‚¬ê³  ë“±)ë¥¼ ë°˜ì˜í•´ë„ ì¢‹ì•„.

[ì°¸ê³ ìë£Œ]
- ì²¨ë¶€ëœ ìë™ì°¨ ë³´í—˜ í‘œì¤€ì•½ê´€ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³ , ê·¸ êµ¬ì¡° ë° í‘œí˜„ë°©ì‹ì„ ë”°ë¼ì¤˜.

[í‘œì¤€ì•½ê´€ ë‚´ìš©]
{all_text}

[ê²°ê³¼]:
"""

        if st.button("ğŸš€ íŠ¹ì•½ ìƒì„± ì‹œì‘"):
            with st.spinner("Potens APIì— ìš”ì²­ ì¤‘ì…ë‹ˆë‹¤..."):
                # ai_service ëª¨ë“ˆì˜ retry_ai_call í•¨ìˆ˜ ì‚¬ìš©
                response_dict = ai_service.retry_ai_call(prompt, POTENS_API_KEY)
                answer = ai_service.clean_ai_response_text(response_dict.get("text", response_dict.get("error", "AI ì‘ë‹µ ì‹¤íŒ¨.")))

            st.markdown("### âœ… ìƒì„±ëœ íŠ¹ì•½")
            st.markdown(answer)
